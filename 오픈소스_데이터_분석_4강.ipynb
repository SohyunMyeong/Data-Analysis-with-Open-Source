{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohyunMyeong/Data-Analysis-with-Open-Source/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_4%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 오픈소스 기반 데이터 분석 4강 - 데이터 수집\n"
      ],
      "metadata": {
        "id": "DkPKaAsoRq5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-1 CSV 파일 읽기"
      ],
      "metadata": {
        "id": "-I7BVVlnRrB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "## data.csv 파일 읽기\n",
        "# 글자 깨짐 방지하기 위해 encoding 옵션 넣기\n",
        "# csv파일은 각각의 데이터 요소들이 , 구분자로 구분\n",
        "# csv는 구글 코랩에서는 엑설처럼 보이지만 실질적으로는 텍스트 파일이고 각각의 값이 ,로 구분된 연속이라고 보면 됨\n",
        "# 제목에 해당하는 줄(=스키마 라고 함)이 한 줄 띄고 그 다음 줄에 썼을 때 눈으로 볼 때 더 편안할 수 있음 그런 경우에는\n",
        "# header가 첫번쨰 줄이 아닌 여러번째 줄에 있을 수 있음 그런 경우를 대비하기 위해 header 옵션 통해 지정\n",
        "# 여러 줄에 header가 있으면 그 값을 1, 2 등으로 바꿔 주는 것\n",
        "# 그 이후 옵션들 그 외에 불필요한 몇몇개의 행을 뛰어 넘고 읽으려고 할 때 사용하는 옵션\n",
        "# 이러한 옵션들 항상 쓰이는건 아니지만 파일이 정상적으로 읽히지 않을 때 사용할 수 있어야 함\n",
        "# 아래 옵션들 해당하는 옵션들의 기본 값이기 때문에 옵션 없을 때와 똑같은 결과 나옴\n",
        "df = pd.read_csv('data.csv', encoding='utf-8', sep = ',', header=0,\n",
        "                 index_col=None, skiprows=None, nrows=None )\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "2Y2HEiaiRwAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba761dd1-8a06-487a-e8c4-9e7f23e832bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           날짜    체중  골격근량  체지방량\n",
            "0  2025.02.06  64.7  30.0  11.1\n",
            "1  2025.02.04  64.0  29.3  11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-2 JSON 파일 읽기\n",
        "\n"
      ],
      "metadata": {
        "id": "9kHCFaGlRrE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# JSON 자바스크립트언어에서 객체를 기록하기 위한 텍스트 형식\n",
        "\n",
        "## data.json 파일 출력\n",
        "# 파일을 읽은 다음 텍스트 파일로 읽어서 json Library로 로드하는 경우\n",
        "# 파일을 읽고 파이썬안에 내장되어있는 제이슨 라이브러리를 통해 읽기\n",
        "# 파이썬 파일 열기\n",
        "# 연 파일 객체의 이름을 as뒤에 기술\n",
        "\n",
        "with open('data.json', mode='r', encoding='utf-8') as f:\n",
        "    # json으로 읽어들인 파일을 객체화 하기 위해 load()함수\n",
        "    # 첫번째 인자로서 앞에서 열었던 파일 f 넣어주면 됨, data에 저장\n",
        "    # jsonlines 파일처럼 한줄로 쭉 읽힘.\n",
        "    data = json.load(f)\n",
        "print(data)\n",
        "\n",
        "## data.json 파일 DataFrame 읽기\n",
        "# 파일을 읽은 다음 DataFrame으로 만든 것 => 출력했더니 관계형 데이터베이스의 테이블 모양으로 나옴\n",
        "# json 파일을 기록할 때 크게 두 가지로 나뉘는데\n",
        "# 객체를 큰 하나의 리스트에 담아서 관리하는 방법(하나의 객체로서 파일을 만듦) =>linesfalse 보통 json파일이라고 하면 false인 파일 형식\n",
        "# or 줄별로 다른 객체들을 저장하는 방법 => jsonlines라는 포맷\n",
        "df = pd.read_json('data.json', orient='records',encoding='utf-8')\n",
        "print(df)"
      ],
      "metadata": {
        "id": "IO8bsKekR0W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395a2c2c-7e57-45c4-8d04-bba55db16267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'매출데이터': [{'월': '2025-01', '매출액': 1000000, '비용': 700000, '이익': 300000}, {'월': '2025-02', '매출액': 1200000, '비용': 800000, '이익': 400000}, {'월': '2025-03', '매출액': 1500000, '비용': 900000, '이익': 600000}]}\n",
            "                                               매출데이터\n",
            "0  {'월': '2025-01', '매출액': 1000000, '비용': 700000,...\n",
            "1  {'월': '2025-02', '매출액': 1200000, '비용': 800000,...\n",
            "2  {'월': '2025-03', '매출액': 1500000, '비용': 900000,...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-3 텍스트 파일 읽기 및 데이터 추출"
      ],
      "metadata": {
        "id": "uLd_3A_IRrHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "## 파일(callcenter20250301.log) 오픈 및 읽기\n",
        "with open('callcenter20250301.log', 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "## 주민등록번호 패턴 생성 (정규식 통해 검출)\n",
        "# 주민번호와 같이 명확한 패턴을 가진 경우 정규식 통해 간편하게 인식 할 수 있음\n",
        "# 텍스트에서 특정 패턴 찾아내기\n",
        "# 정규식을 만들기 위해선 regular expression 정규식 라이브러리 안에 complie 함수 사용 정규식을 이용해서 인식하는 함수 만들 수 있음\n",
        "# 어떤 패턴을 읽을건지 정규 표현식을 통해 명시를 해주게 되어있음\n",
        "# 정규표현식은 r이라는 키워드가 앞에 붙은 string 형태 6자리의 숫자-7자리의 숫자\n",
        "# 마스킹할 때 앞에것과 뒤에것을 다르게 할 것이기 때문에 괄호를 묶어 앞에자리 6개를 첫번째 그룹 뒤에자리 7개를 두번째그룹으로 인식하는 정규표현식을 만듦\n",
        "pattern = re.compile(r'(\\d{6})-(\\d{7})')\n",
        "\n",
        "## 주민등록번호 마스킹\n",
        "# 패턴만들어 적용해서 저 규칙에 나오는 텍스트 있으면 마스킹\n",
        "# 패턴 생성했으니 패턴을 통해서 앞에서 읽은 content에 있는 모든걸 살펴보고 패턴에 매칭되어있는 것을 바꿔주는 코드\n",
        "# 치환함수 sub, 인자는 치환된 결과가 어떻게 바뀌는지 먼저 기술 ,무엇을 치환할 것인지를 두번째 인자\n",
        "# 위에 만들어둔 (\\d{6})-> 첫번째 그룹 -> 첫번쨰 그룹을 뜻하는 것은 \\1 이렇게 기술할 수 있음\n",
        "# 첫번째 그룹의 여섯개 숫자는 그대로 쓰고 7개만 *로 변경\n",
        "# 이렇게 하면 컨텐츠에 있는 마스킹 되어있는 것들이 새로운 객체로 반환 됨\n",
        "masked_content = pattern.sub(r'\\1-*******', content)\n",
        "\n",
        "## 마스킹된 파일(callcenter20250301_masked.log) 오픈 및 쓰기\n",
        "with open('callcenter20250301_masked.log', mode='w') as f:\n",
        "    f.write(masked_content)\n",
        "\n",
        "print(\"주민등록번호 마스킹 완료. 'callcenter20250301_masked.log.txt' 파일로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "60qOf7uxVdAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8608a3-b560-4c2e-e71b-42e4b634fc04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주민등록번호 마스킹 완료. 'callcenter20250301_masked.log.txt' 파일로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-4 Open-Meteo의 무료 날씨 API를 통한 특정 지역 온도 조회"
      ],
      "metadata": {
        "id": "eOMufu5SXiAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requests 라이브러리를 통해 정보를 가져오기, json 라이브러리를 통해 파이썬 객체로 변환\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# api 파일이 아닌 인터넷 사이트로 접속해서 정보를 실시간으로 받아 오는 것\n",
        "# Open-Meteo 특정 위도, 경도의 날씨 값 제공 해줌 (가입, 인증 필요 X)\n",
        "url = \"https://api.open-meteo.com/v1/forecast?=&=&current=temperature_2m\"\n",
        "params = {\n",
        "    \"latitude\": \"37.58638333\",\n",
        "    \"longitude\": \"127.0203333\",\n",
        "    \"current\": \"temperature_2m\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    ## URL 및 파라미터 전송\n",
        "    # 인터넷에 있는 정보 url 통해 갖고 오기 위해 request 라이브러리 사용\n",
        "    # 인자 값 - 어디에 위치한 정보인지 나타내주는 url, 어떤 인자 값을 넘길지 뜻하는 params\n",
        "    response = requests.get(url, params = params)\n",
        "    # 사이트의 정보를 가져올 때 상태값 나타내기\n",
        "    # 상태값을 판단해서 오류시 알려주기\n",
        "    response.raise_for_status()\n",
        "\n",
        "    ## JSON 데이터 읽기\n",
        "    # 인터넷에서 받아온 정보 JSON 객체로 변환\n",
        "    # JSON -> 파이썬 객체로 변환하는거 requests 라이브러리에 있음 여기선 requests 사용\n",
        "    data = response.json()\n",
        "\n",
        "    print(\"API 응답:\", data)\n",
        "    print(\"서울시 종로구의 현재 온도는 : {0}{1} 입니다.\".format(data['current']['temperature_2m'], data['current_units']['temperature_2m']))\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"API 호출 실패: {e}\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"JSON 파싱 실패: {e}\")"
      ],
      "metadata": {
        "id": "JpmgdsW9V0CY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c50777-43af-47fd-8fef-00b679eaccd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 응답: {'latitude': 37.6, 'longitude': 127.0, 'generationtime_ms': 0.023484230041503906, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 29.0, 'current_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature_2m': '°C'}, 'current': {'time': '2025-09-03T02:00', 'interval': 900, 'temperature_2m': 27.2}}\n",
            "서울시 종로구의 현재 온도는 : 27.2°C 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-5 Selenium과 lxml을 이용한 웹 스크래핑"
      ],
      "metadata": {
        "id": "RLfPaa1ZiqIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹 스크래핑 사용하기 위해서는 웹 컨텐츠 접속하고 내용 가져오기 위해서 웹 브라우저 사용 웹 브라우저 제어하는 Selenium 사용\n",
        "# 그걸 통해 HTML을 가져오면 lxml이라는 라이브러릴 사용해 안에 있는 내용을 가져옴\n",
        "\n",
        "# 웹사이트에서 구글 크롬에 설치 파일 다운로드 받기\n",
        "!curl -o google-chrome-stable_current_amd64.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "# 리눅스 명령어인 apt를 통해 설치\n",
        "!apt install ./google-chrome-stable_current_amd64.deb -y\n",
        "!pip install selenium webdriver_manager"
      ],
      "metadata": {
        "id": "79dmM7MNk8pB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9f497d-574d-4c26-d15f-50d2f0313e17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  115M  100  115M    0     0   266M      0 --:--:-- --:--:-- --:--:--  266M\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 10.9 MB/131 MB of archives.\n",
            "After this operation, 447 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 140.0.7339.80-1 [121 MB]\n",
            "Fetched 10.9 MB in 2s (5,487 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (140.0.7339.80-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (140.0.7339.80-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Collecting typing_extensions~=4.14.0 (from selenium)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (25.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver_manager) (3.4.3)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, typing_extensions, outcome, webdriver_manager, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 webdriver_manager-4.0.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API는 정형화된 형태로 데이터를 받아서 활용\n",
        "# 웹 스크래핑은 HTML로 저장이 되어있는 웹페이지를 다운받고 필요한 정보를 사용할 때 사용하는 기술\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from lxml import html\n",
        "import time\n",
        "\n",
        "# 크롬에 관련된 여러가지 옵션\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "# Selenium 실제 웹브라우저가 여러분들 화면 앞에서 자동적으로 조작하도록 하는 라이브러리인데 크롬에서 실행하다보니\n",
        "# 웹브라우저가 이면에 숨음 -> 가상으로만 실행 -> 그걸 headless로 만드는 과정\n",
        "chrome_options.add_argument('--headless')               # 브라우저 창 없이 실행\n",
        "chrome_options.add_argument('--no-sandbox')             # 보안모드 비활성화 (Colab 필수)\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # 메모리 부족 방지 (Colab 필수)\n",
        "chrome_options.add_argument('--window-size=1920x1080')  # 창 크기 설정(가상)\n",
        "chrome_options.add_argument('--disable-gpu')            # GPU 가속 비활성화 (일부 환경 안정성)\n",
        "chrome_options.binary_location = \"/usr/bin/google-chrome-stable\"  # Colab용 크롬 경로 지정\n",
        "\n",
        "## 드라이버 실행\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "## 사이트 접속\n",
        "url = 'https://professor.knou.ac.kr/jaehwachung/index.do'\n",
        "# 드라이버에서 get 프로토콜을 통해 url 접속\n",
        "# 보이진 않지만 눈에 보이지 않는 크롬 사이트에서 해당 웹페이지가 떠서 접속하게 함\n",
        "driver.get(url)\n",
        "\n",
        "## 사이트 접속 대기\n",
        "# 사이트가 뜨는 시간이 있기 때문에 페이지가 로드 되는 시간을 기다려 주기 위해서 2초정도 지연 줌\n",
        "# 지연 안 주면 정상적으로 데이터 스크래핑 안될수도 음\n",
        "time.sleep(2)\n",
        "\n",
        "## 페이지 제목 출력\n",
        "# 웹페이지의 소스는 driver.page_source에 위채 되어 있음\n",
        "page_source = driver.page_source\n",
        "# 데이터 가져온거 분석하기 위해 tree 형태로 페이지 변환하기\n",
        "# lxml에서 import 했던 html이라는 분석기를 통해 tree 형태로 변환\n",
        "# url로 들어가면 보이는 페이지 자체를 html로 받아서 tree 형태로 변환\n",
        "tree = html.fromstring(page_source)\n",
        "\n",
        "# xpath를 통해 tree안에 있는 특정 요소를 갖고 옴\n",
        "# 루트 부터 차례대로 탐색하는데 타이틀이라는 태그를 탐색하고 여기 안에 있는 텍스트 추출\n",
        "title_text = tree.xpath('//title/text()')\n",
        "print(title_text)\n",
        "\n",
        "## 드라이버 종료\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "cRC8x3_iW0im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4316b56e-fcdd-484c-80be-fad29c827fd0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n\\t\\tAlert \\n\\t\\t\\n\\t']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 실습 시나리오"
      ],
      "metadata": {
        "id": "Bu6OMZyGirOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공공데이터 포털 가입 및 데이터 신청\n",
        "\n",
        "- [https://www.data.go.kr](https://www.data.go.kr)\n",
        "- 한국환경공단 에어코리아 대기오염정보 데이터 신청"
      ],
      "metadata": {
        "id": "nsuqRN9RkZlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "## 데이터 수집 url 및 api key 설정\n",
        "\n",
        "\n",
        "params = {\n",
        "    'serviceKey': api_key,\n",
        "    'returnType': 'json',\n",
        "    'numOfRows': '100',\n",
        "    'pageNo': '1',\n",
        "    'sidoName': '서울',\n",
        "    'ver': '1.0'\n",
        "}\n",
        "\n",
        "## 데이터 수집\n",
        "\n",
        "## 호출 성공/실패 출력\n",
        "\n"
      ],
      "metadata": {
        "id": "7yCozmQeXJcO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}